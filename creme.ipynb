{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering\n",
    "\n",
    "I'll start by installing the Creme library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall creme -y\n",
    "# !pip install git+https://github.com/creme-ml/creme --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install creme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm importing the packages that I'm going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import metrics\n",
    "from creme import neighbors\n",
    "from creme import preprocessing\n",
    "from creme import stats\n",
    "from creme import stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use this first function to parse the date and extract the number of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(x):\n",
    "    \"\"\"Extract features from the date.\"\"\"\n",
    "    import datetime\n",
    "    if not isinstance(x['date'], datetime.datetime):\n",
    "        x['date'] = datetime.datetime.strptime(x['date'], '%Y-%m-%d')\n",
    "    x['wday'] = x['date'].weekday()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``get_metadata`` allows you to extract the identifier of the product and the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(x):\n",
    "    key = x['id'].split('_')\n",
    "    x['store_id'] = f'{key[3]}_{key[4]}'\n",
    "    x['item_id'] = f'{key[0]}_{key[1]}_{key[2]}'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define the feature extraction pipeline. I use the module ``feature_extraction.TargetAgg`` to calculate the features on the target variable of the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = compose.TransformerUnion(\n",
    "    compose.Select('wday'),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(7) | stats.Mean()),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(7) | stats.Var()),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.Shift(7) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.Shift(7) | stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.Shift(7) | stats.RollingMean(7)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(7) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(7) | stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(7) | stats.RollingMean(7)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.Shift(7) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.Shift(7) | stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.Shift(7) | stats.RollingMean(7)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I define the global pipeline I want to deploy in production. The pipeline is composed of:\n",
    "\n",
    "- Extraction of the product identifier.\n",
    "\n",
    "- Extraction of the day number of the date $\\in$ {1, 2, ..7}. \n",
    "\n",
    "- Computation of the features.\n",
    "\n",
    "- Standard scaler that centers and reduces the value of features.\n",
    "\n",
    "- Model declaration ``neighbors.KNeighborsRegressor``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    neighbors.KNeighborsRegressor(window_size=30, n_neighbors=15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have choosen to create one model per product. The piece of code below creates a copy of the pipeline for all products and store them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60980it [00:02, 26285.58it/s]\n",
      "100%|██████████| 3049/3049 [00:05<00:00, 531.69it/s]\n"
     ]
    }
   ],
   "source": [
    "list_model = []\n",
    "\n",
    "X_y = stream.iter_csv('./data/sample_submission.csv', target_name='F8')\n",
    "\n",
    "for x, y in tqdm.tqdm(X_y, position=0):\n",
    "    \n",
    "    item_id = '_'.join(x['id'].split('_')[:3])\n",
    "    \n",
    "    if item_id not in list_model:\n",
    "    \n",
    "        list_model.append(item_id)\n",
    "        \n",
    "dic_models = {item_id: copy.deepcopy(model) for item_id in tqdm.tqdm(list_model, position=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3049"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do a warm-up of all the models from a subset of the training set. To do this pre-training, I selected the last two months of the training set and saved it in csv format.I use Creme's ``stream.iter_csv`` module to iterate on the training dataset. The pipeline below consumes very little RAM memory because we load the data into the memory one after the other. I train my models to predict sales 7 days in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MAE: 1.274888: : 1092817it [09:38, 1774.50it/s]"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "params = dict(target_name='y', converters={'y': int, 'id': str}, parse_dates= {'date': '%Y-%m-%d'})\n",
    "\n",
    "X_y = stream.simulate_qa(\n",
    "    X_y    = stream.iter_csv('./data/train_preprocessed.csv', **params), \n",
    "    moment = 'date', \n",
    "    delay  = datetime.timedelta(days=7)\n",
    ")\n",
    "\n",
    "bar = tqdm.tqdm(X_y, position = 0)\n",
    "\n",
    "metric = metrics.Rolling(metrics.MAE(), 600000)\n",
    "\n",
    "y_pred = {}\n",
    "\n",
    "for i, x, y in bar:\n",
    "    \n",
    "    item_id  = '_'.join(x['id'].split('_')[:3])\n",
    "    \n",
    "    if y != None:\n",
    "\n",
    "        dic_models[f'{item_id}'].fit_one(x=x, y=y)\n",
    "        \n",
    "        # Update the metric:\n",
    "        metric = metric.update(y, y_pred[i])\n",
    "           \n",
    "        if i % 1000 == 0:\n",
    "            # Update tqdm progress bar.\n",
    "            bar.set_description(f'MAE: {metric.get():4f}')\n",
    "\n",
    "    else:\n",
    "\n",
    "        y_pred[i] = dic_models[f'{item_id}'].predict_one(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# MAE: 1.101585: : 3658800 [26:13, 2324.70it/s]\n",
    "\n",
    "# LR\n",
    "#MAE: 1.307144: : 3658800it [19:04, 3197.18it/s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models after training with dill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dic_model_knn_lag.dill', 'wb') as file:\n",
    "    dill.dump(dic_models, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment of the model:\n",
    "\n",
    "**Now that all the models are pre-trained, I will be able to deploy the pipelines behind an API in a production environment. I will use the [Chantilly](https://github.com/creme-ml/chantilly) library to do so.**\n",
    "\n",
    "**[Chantilly](https://github.com/creme-ml/chantilly) is a project that aims to ease train Creme models when they are deployed. Chantilly is a minimalist API based on the Flask framework.** Chantilly allows to make predictions, train models and measure model performance in real time. It gives access to a dashboard.\n",
    "\n",
    "Chantilly is a library currently under development. For various reasons, I choose to extract the files from Chantilly that I'm interested in to realize this project.\n",
    "\n",
    "I choose to deploy my API on Heroku. To do so I followed the [tutorial](https://stackabuse.com/deploying-a-flask-application-to-heroku/). I choose Heroku because they allow me to run my API with a very modest configuration at a low cost. (This modest configuration increases the response time of my API when there are several users). With a budget bigger than mine, my API could handle a large volume of requests simultaneously.\n",
    "\n",
    "The main difficulty I encountered when deploying on Heroku was creating the ``Profile`` file. The ``Procfile`` is used to initialize the API when it is deployed on Heroku.\n",
    "\n",
    "Here is its contents:\n",
    "\n",
    "```web: gunicorn -w 4 \"app:create_app()\"```\n",
    "\n",
    "You will be able to find the whole architecture of my API [here](https://github.com/raphaelsty/M5-Forecasting-Accuracy).\n",
    "\n",
    "After deploying my Chantilly API on Heroku, I add the regression flavor. Chantilly uses this flavor to select the appropriate metrics (MAE, MSE and SMAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kaggle-creme-ml.herokuapp.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "requests.post(f'{url}/api/init', json= {'flavor': 'regression'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the flavor of my API, I upload all the models I've pre-trained. Each model has a name. This name is the name of the product. I have used dill to serialize the model before uploading it to my API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dic_models.dill', 'rb') as file:\n",
    "    dic_models = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3049/3049 [23:06<00:00,  2.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in tqdm.tqdm(dic_models.items(), position=0):\n",
    "    r = requests.post(f'{url}/api/model/{model_name}', data=dill.dumps(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are now deployed in production and available to make predictions. The models can also be updated on a daily basis. That's it.\n",
    "\n",
    "![](static/online_learning.png)\n",
    "\n",
    "**As you may have noticed, the philosophy of online learning allows to reduce the complexity of the deployment of a machine learning algorithm in production. Moreover, to update the model, we only have to make calls to the API. We don't need to re-train the model from scratch.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction by calling the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/predict', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001',\n",
    "    'features': {'date': '2016-05-23', 'id': 'HOBBIES_1_001_CA_1'}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'HOBBIES_1_001', 'prediction': 0.8351625255839868}\n"
     ]
    }
   ],
   "source": [
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can execute these requests. I don't recommend that you request my models to blend my predictions to yours. My models are not intended to be competitive. \n",
    "\n",
    "If you want my opinion on the competition, I think there's a lot of noise in the data. I haven't observed any particular trends when it comes to day-to-day predictions for all products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update models with new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/learn', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001',\n",
    "    'ground_truth': 1,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
