{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering\n",
    "\n",
    "I'll start by installing the Creme library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install git+https://github.com/creme-ml/creme --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm importing the packages that I'm going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import metrics\n",
    "from creme import optim\n",
    "from creme import preprocessing\n",
    "from creme import stats\n",
    "from creme import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import neighbors\n",
    "from creme import tree\n",
    "from creme import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use this first function to parse the date and extract the number of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(x):\n",
    "    \"\"\"Extract features from the date.\"\"\"\n",
    "    import datetime\n",
    "    if not isinstance(x['date'], datetime.datetime):\n",
    "        x['date'] = datetime.datetime.strptime(x['date'], '%Y-%m-%d')\n",
    "    x['wday'] = x['date'].weekday()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``get_metadata`` allows you to extract the identifier of the product and the store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(x):\n",
    "    key = x['id'].split('_')\n",
    "    x['store_id'] = f'{key[3]}_{key[4]}'\n",
    "    x['item_id'] = f'{key[0]}_{key[1]}_{key[2]}'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I define the feature extraction pipeline. I use the module ``feature_extraction.TargetAgg`` to calculate the features on the target variable of the stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = compose.TransformerUnion(\n",
    "    compose.Select('wday'),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Mean()),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Var()),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id', 'wday'], how=stats.Mean()),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'wday'], how=stats.Var()),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(7)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(30)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(15)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.RollingMean(20)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(30) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(29) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(28) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(27) | stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id'], how=stats.Shift(26) | stats.RollingMean(1)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(7)),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(30)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(15)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'store_id'], how=stats.RollingMean(20)),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I define the global pipeline I want to deploy in production. The pipeline is composed of:\n",
    "\n",
    "- Extraction of the product identifier.\n",
    "\n",
    "- Extraction of the day number of the date $\\in$ {1, 2, ..7}. \n",
    "\n",
    "- Computation of the features.\n",
    "\n",
    "- Standard scaler that centers and reduces the value of features.\n",
    "\n",
    "- Model declaration ``neighbors.KNeighborsRegressor``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    neighbors.KNeighborsRegressor(window_size=300, n_neighbors=30, p=2)\n",
    ")\n",
    "\n",
    "lm = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    linear_model.LinearRegression(optimizer=optim.SGD(0.00005), clip_gradient=1, intercept_lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have choosen to create one model per product. The piece of code below creates a copy of the pipeline for all products and store them in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60980it [00:01, 33220.40it/s]\n",
      "100%|██████████| 3049/3049 [00:06<00:00, 460.29it/s]\n",
      "100%|██████████| 3049/3049 [00:05<00:00, 541.71it/s]\n"
     ]
    }
   ],
   "source": [
    "list_model = []\n",
    "\n",
    "X_y = stream.iter_csv('./data/sample_submission.csv', target_name='F8')\n",
    "\n",
    "for x, y in tqdm.tqdm(X_y, position=0):\n",
    "    \n",
    "    item_id = '_'.join(x['id'].split('_')[:3])\n",
    "\n",
    "    if item_id not in list_model:\n",
    "\n",
    "        list_model.append(item_id)\n",
    "        \n",
    "dict_knn = {item_id: copy.deepcopy(knn) for item_id in tqdm.tqdm(list_model, position=0)}\n",
    "dict_lm  = {item_id: copy.deepcopy(lm) for item_id in tqdm.tqdm(list_model, position=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do a warm-up of all the models from a subset of the training set. To do this pre-training, I selected the last two months of the training set and saved it in csv format.I use Creme's ``stream.iter_csv`` module to iterate on the training dataset. The pipeline below consumes very little RAM memory because we load the data into the memory one after the other. I train my models to predict sales 7 days in advance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1829400it [14:54:19, 34.09it/s] \n"
     ]
    }
   ],
   "source": [
    "import collections \n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "params = dict(target_name='y', converters={'y': int, 'id': str}, parse_dates= {'date': '%Y-%m-%d'})\n",
    "\n",
    "X_y = stream.iter_csv('./data/train_preprocessed.csv', **params)\n",
    "\n",
    "bar = tqdm.tqdm(X_y, position = 0)\n",
    "\n",
    "metric_knn = collections.defaultdict(lambda: metrics.MAE())\n",
    "metric_lm  = collections.defaultdict(lambda: metrics.MAE())\n",
    "\n",
    "for i, (x, y) in enumerate(bar):\n",
    "    \n",
    "    item_id  = '_'.join(x['id'].split('_')[:3])\n",
    "\n",
    "    y_pred_knn = dict_knn[f'{item_id}'].predict_one(x)\n",
    "    \n",
    "    y_pred_lm  = dict_lm[f'{item_id}'].predict_one(x)\n",
    "\n",
    "    metric_knn[f'{item_id}'].update(y, y_pred_knn)\n",
    "    \n",
    "    metric_lm[f'{item_id}'].update(y, y_pred_lm)\n",
    "\n",
    "    dict_knn[f'{item_id}'].fit_one(x=x, y=y)\n",
    "    \n",
    "    # Train linear model for 10 epochs on each training example\n",
    "    for _ in range(10):\n",
    "        \n",
    "        dict_lm[f'{item_id}'].fit_one(x=x, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save scores of models for each product after training the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "scores_knn = {id: _.get() for id, _ in metric_knn.items()}\n",
    "scores_lm  = {id: _.get() for id, _ in metric_lm.items()}\n",
    "\n",
    "with open('scores_knn.json', 'w') as file:\n",
    "    \n",
    "    json.dump(scores_knn, file)\n",
    "\n",
    "with open('scores_lm.json', 'w') as file:\n",
    "    \n",
    "    json.dump(scores_lm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3049/3049 [00:00<00:00, 165462.52it/s]\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "for item_id in tqdm.tqdm(scores_knn.keys()):\n",
    "    \n",
    "    score_knn = scores_knn[item_id]\n",
    "    \n",
    "    score_lm  = scores_lm[item_id]\n",
    "    \n",
    "    if score_knn < score_lm:\n",
    "        \n",
    "        scores[item_id] = score_knn\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        scores[item_id] = score_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sum({value for key, value in scores_knn.items()}) / 3049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('dict_knn.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_knn, file)\n",
    "    \n",
    "with open('dict_lm.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_lm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load scores and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('scores_knn.json', 'rb') as file:\n",
    "    \n",
    "    scores_knn = json.load(file)\n",
    "\n",
    "with open('scores_lm.json', 'rb') as file:\n",
    "    \n",
    "    scores_lm = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('dict_knn.dill', 'rb') as file:\n",
    "    \n",
    "    dict_knn = dill.load(file)\n",
    "    \n",
    "with open('dict_lm.dill', 'rb') as file:\n",
    "    \n",
    "    dict_lm = dill.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each product, we chosse the best model between KNNRegressor and linear model depending on the validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3049/3049 [00:00<00:00, 8539.32it/s]\n"
     ]
    }
   ],
   "source": [
    "dict_model = {}\n",
    "\n",
    "for item_id in tqdm.tqdm(scores_knn.keys()):\n",
    "    \n",
    "    score_knn = scores_knn[item_id]\n",
    "    \n",
    "    score_lm  = scores_lm[item_id]\n",
    "    \n",
    "    if score_knn < score_lm:\n",
    "        \n",
    "        dict_model[item_id] = dict_knn[item_id]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dict_model[item_id] = dict_lm[item_id]\n",
    "        \n",
    "# Save selected models:\n",
    "with open('dict_model.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment of the model:\n",
    "\n",
    "**Now that all the models are pre-trained, I will be able to deploy the pipelines behind an API in a production environment. I will use the [Chantilly](https://github.com/creme-ml/chantilly) library to do so.**\n",
    "\n",
    "**[Chantilly](https://github.com/creme-ml/chantilly) is a project that aims to ease train Creme models when they are deployed. Chantilly is a minimalist API based on the Flask framework.** Chantilly allows to make predictions, train models and measure model performance in real time. It gives access to a dashboard.\n",
    "\n",
    "Chantilly is a library currently under development. For various reasons, I choose to extract the files from Chantilly that I'm interested in to realize this project.\n",
    "\n",
    "I choose to deploy my API on Heroku. To do so I followed the [tutorial](https://stackabuse.com/deploying-a-flask-application-to-heroku/). I choose Heroku because they allow me to run my API with a very modest configuration at a low cost. (This modest configuration increases the response time of my API when there are several users). With a budget bigger than mine, my API could handle a large volume of requests simultaneously.\n",
    "\n",
    "The main difficulty I encountered when deploying on Heroku was creating the ``Profile`` file. The ``Procfile`` is used to initialize the API when it is deployed on Heroku.\n",
    "\n",
    "Here is its contents:\n",
    "\n",
    "```web: gunicorn -w 4 \"app:create_app()\"```\n",
    "\n",
    "You will be able to find the whole architecture of my API [here](https://github.com/raphaelsty/M5-Forecasting-Accuracy).\n",
    "\n",
    "After deploying my Chantilly API on Heroku, I add the regression flavor. Chantilly uses this flavor to select the appropriate metrics (MAE, MSE and SMAPE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://kaggle-creme-ml.herokuapp.com'\n",
    "#url = 'http://0.0.0.0:5000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "requests.post(f'{url}/api/init', json= {'flavor': 'regression'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing the flavor of my API, I upload all the models I've pre-trained. Each model has a name. This name is the name of the product. I have used dill to serialize the model before uploading it to my API."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('dic_models.dill', 'rb') as file:\n",
    "    dic_models = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3049 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in tqdm.tqdm(dic_models.items(), position=0):\n",
    "    r = requests.post(f'{url}/api/model/{model_name}', data=dill.dumps(model))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOBBIES_1_001'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are now deployed in production and available to make predictions. The models can also be updated on a daily basis. That's it.\n",
    "\n",
    "![](static/online_learning.png)\n",
    "\n",
    "**As you may have noticed, the philosophy of online learning allows to reduce the complexity of the deployment of a machine learning algorithm in production. Moreover, to update the model, we only have to make calls to the API. We don't need to re-train the model from scratch.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction by calling the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/predict', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001',\n",
    "    'features': {'date': '2016-05-23', 'id': 'HOBBIES_1_001_CA_1'}\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can execute these requests. I don't recommend that you request my models to blend my predictions to yours. My models are not intended to be competitive. \n",
    "\n",
    "If you want my opinion on the competition, I think there's a lot of noise in the data. I haven't observed any particular trends when it comes to day-to-day predictions for all products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update models with new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/learn', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001',\n",
    "    'ground_truth': 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [400]>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct(x):\n",
    "    yield from x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_treshold(k):\n",
    "\n",
    "    gen1 = funct([1, 2, 3, 4])\n",
    "    gen2 = funct([5, 6, 7, 8])\n",
    "\n",
    "    for bar1, bar2 in zip(gen1, gen2):\n",
    "        if bar1 > k:\n",
    "            yield bar1, bar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 7\n",
      "4 8\n"
     ]
    }
   ],
   "source": [
    "for bar1, bar2 in gen_treshold(2):\n",
    "    print(bar1, bar2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookahead(iterable):\n",
    "    \"\"\"Pass through all values from the given iterable, augmented by the\n",
    "    information if there are more values to come after the current one\n",
    "    (True), or if it is the last value (False).\n",
    "    \"\"\"\n",
    "    # Get an iterator and pull the first value.\n",
    "    it = iter(iterable)\n",
    "    last = next(it)\n",
    "    # Run the iterator to exhaustion (starting from the second value).\n",
    "    for val in it:\n",
    "        # Report the *previous* value (more to come).\n",
    "        yield last, True\n",
    "        last = val\n",
    "    # Report the last value.\n",
    "    yield last, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, True)\n",
      "(2, True)\n",
      "(3, False)\n"
     ]
    }
   ],
   "source": [
    "for i in lookahead([1, 2, 3]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
