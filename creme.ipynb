{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import pickle\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import linear_model\n",
    "from creme import metrics\n",
    "from creme import optim\n",
    "from creme import preprocessing\n",
    "from creme import stats\n",
    "from creme import stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get informations on dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(x):\n",
    "    if not isinstance(x['date'], dt.datetime):\n",
    "        x['date'] = dt.datetime.strptime(x['date'], '%Y-%m-%d')\n",
    "    x['month'] = x['date'].month\n",
    "    x['wday'] = x['date'].weekday()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metadata of the product: cat_id, dept_id, item_id, state_id and store id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(x):\n",
    "    key = x['id'].split('_')\n",
    "    x['cat_id'] = f'{key[0]}'\n",
    "    x['dept_id'] = f'{x[\"cat_id\"]}_{key[1]}'\n",
    "    x['item_id'] = f'{x[\"cat_id\"]}_{x[\"dept_id\"]}_{key[2]}'\n",
    "    x['state_id'] = f'{key[3]}'\n",
    "    x['store_id'] = f'{x[\"state_id\"]}_{key[4]}'\n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``compose.Select`` method is used to select the features that will be used to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection = compose.Select('wday', 'month', 'sell_price', 'snap_CA', 'snap_TX', 'snap_WI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the features we have selected, we will build aggregates to improve the performance of the model. I have built multiple aggregates based on the metadata of each product such as target encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = compose.TransformerUnion([\n",
    "    feature_selection,\n",
    "    # Feature based on sell_price.\n",
    "    feature_extraction.Agg('sell_price', 'store_id', how=stats.Mean()),\n",
    "    feature_extraction.Agg('sell_price', 'item_id', how=stats.Mean()),\n",
    "    feature_extraction.Agg('sell_price', ['store_id', 'item_id'], how=stats.Mean()),\n",
    "    # Target encoding based on item, and dates.\n",
    "    feature_extraction.TargetAgg(by='item_id', how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['wday', 'item_id'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['month', 'item_id'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    # Target encoding based on store.\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'item_id'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'cat_id'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'wday', 'item_id'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    # Target encoding based on event_name, event_type and store_id.\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'event_name_1'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'event_name_2'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'event_type_1'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['store_id', 'event_type_2'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    # Target encoding based on item_id, and event_name.\n",
    "    feature_extraction.TargetAgg(by=['item_id', 'event_name_1'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "    feature_extraction.TargetAgg(by=['item_id', 'event_name_2'], how=stats.BayesianMean(prior=0, prior_weight=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline we define is composed of:\n",
    "\n",
    "- A function that extracts ```metadata``` related to the item.\n",
    "- Function that extracts ```the month``` and ```the day number, ie {'Monday': 1, 'Tuesday': 2}```. \n",
    "- Function that extracts the ```features based on the targets we are trying to predict and on the price of items```.\n",
    "- ```Standard scaler``` to center reduce features before updating the model.\n",
    "- ```Linear regression``` using ```stocastic gradient descent``` as an optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LinearRegression(\n",
    "        intercept=0,\n",
    "        optimizer=optim.SGD(0.00001),\n",
    "        intercept_lr=0.0005\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MAE: 1.353164: : 14419it [00:10, 1409.92it/s]"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "\n",
    "params = dict(\n",
    "    target_name='y', \n",
    "    converters={\n",
    "        'y': int, \n",
    "        'sell_price': float, \n",
    "        'snap_WI': int, \n",
    "        'snap_TX': int, \n",
    "        'snap_CA': int,\n",
    "        'date': str\n",
    "    }\n",
    ")\n",
    "\n",
    "X_y = stream.iter_csv('./data/train.csv', **params)\n",
    "\n",
    "bar = tqdm.tqdm(X_y, position = 0)\n",
    "\n",
    "metric = metrics.Rolling(metrics.MAE(), 100000)\n",
    "\n",
    "for i, (x, y) in enumerate(bar):\n",
    "    \n",
    "    # First predict, we are doing progressive validation.\n",
    "    y_pred = model.predict_one(x)\n",
    "    \n",
    "    # Update the model.\n",
    "    model.fit_one(x=x, y=y)\n",
    "    \n",
    "    # Update the metric.\n",
    "    metric = metric.update(y, y_pred)\n",
    "    \n",
    "    # Update tqdm progress bar every j iterations.\n",
    "    if i % 2000 == 0:\n",
    "        \n",
    "        bar.set_description(f'MAE: {metric.get():4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'linear_regression.pickle', 'wb') as f: \n",
    "    pickle.dump(model, f, pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have defined our pipeline and our model is pre-trained, we will be able to move into production. I will use the Chantilly library to deploy the model in production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
