{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install creme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import collections \n",
    "import datetime\n",
    "import random\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from creme import compose\n",
    "from creme import feature_extraction\n",
    "from creme import linear_model\n",
    "from creme import metrics\n",
    "from creme import neighbors\n",
    "from creme import optim\n",
    "from creme import preprocessing\n",
    "from creme import stats\n",
    "from creme import stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(x):\n",
    "    \"\"\"Extract features from the date.\"\"\"\n",
    "    import datetime\n",
    "    if not isinstance(x['date'], datetime.datetime):\n",
    "        x['date'] = datetime.datetime.strptime(x['date'], '%Y-%m-%d')\n",
    "    x['wday'] = x['date'].weekday()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(x):\n",
    "    key = x['id'].split('_')\n",
    "    x['item_id'] = f'{key[0]}_{key[1]}_{key[2]}'\n",
    "    x['store_id'] = f'{key[3]}_{key[4]}'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features = compose.TransformerUnion(\n",
    "    compose.Select('wday'),\n",
    "    \n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(2)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(4)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(5)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(6)),\n",
    "    feature_extraction.TargetAgg(by=['item_id'], how=stats.RollingMean(7)),\n",
    "\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(1)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(2)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(3)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(4)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(5)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(6)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(7)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(8)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(9)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(10)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(11)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(12)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(13)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(14)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(15)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(16)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(17)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(18)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(19)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(20)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(25)),\n",
    "    feature_extraction.TargetAgg(by=['wday'], how=stats.RollingMean(30)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init pipeline dedicated to KNN\n",
    "knn = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    preprocessing.StandardScaler() |\n",
    "    neighbors.KNeighborsRegressor(window_size=30, n_neighbors=15, p=2)\n",
    ")\n",
    "\n",
    "\n",
    "# Init pipeline dedicated to linear model\n",
    "lm = (\n",
    "    compose.FuncTransformer(get_metadata) |\n",
    "    compose.FuncTransformer(extract_date) |\n",
    "    extract_features |\n",
    "    preprocessing.MinMaxScaler() |\n",
    "    linear_model.LinearRegression(optimizer=optim.SGD(0.005), intercept_lr=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_model = []\n",
    "\n",
    "X_y = stream.iter_csv('./data/sample_submission.csv', target_name='F8')\n",
    "\n",
    "for x, y in tqdm.tqdm(X_y, position=0):\n",
    "    \n",
    "    item_id = '_'.join(x['id'].split('_')[:5])\n",
    "\n",
    "    if item_id not in list_model:\n",
    "\n",
    "        list_model.append(item_id)\n",
    "        \n",
    "dict_knn = {item_id: copy.deepcopy(knn) for item_id in tqdm.tqdm(list_model, position=0)}\n",
    "dict_lm  = {item_id: copy.deepcopy(lm) for item_id in tqdm.tqdm(list_model, position=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "params = dict(\n",
    "    target_name = 'y',\n",
    "    converters  = {'y': int, 'id': str}, \n",
    "    parse_dates = {'date': '%Y-%m-%d'}\n",
    ")\n",
    "\n",
    "# Init streaming csv reader\n",
    "X_y = stream.iter_csv('./data/train.csv', **params)\n",
    "\n",
    "bar = tqdm.tqdm(X_y, position = 0)\n",
    "\n",
    "# Init online metrics:\n",
    "metric_knn = collections.defaultdict(lambda: metrics.MAE())\n",
    "\n",
    "metric_lm  = collections.defaultdict(lambda: metrics.MAE())\n",
    "\n",
    "mae = metrics.MAE()\n",
    "\n",
    "for i, (x, y) in enumerate(bar):\n",
    "    \n",
    "    # Extract item id\n",
    "    item_id  = '_'.join(x['id'].split('_')[:5])\n",
    "    \n",
    "    # KNN\n",
    "\n",
    "    # Evaluate performance of KNN\n",
    "    y_pred_knn = dict_knn[f'{item_id}'].predict_one(x)\n",
    "\n",
    "    # Update metric of KNN\n",
    "    metric_knn[f'{item_id}'].update(y, y_pred_knn)\n",
    "\n",
    "    # Fit KNN\n",
    "    dict_knn[f'{item_id}'].fit_one(x=x, y=y)\n",
    "\n",
    "    # Linear Model\n",
    "\n",
    "    # Evaluate performance of linear model\n",
    "    y_pred_lm  = dict_lm[f'{item_id}'].predict_one(x)\n",
    "\n",
    "    # Update metric of linear model\n",
    "    metric_lm[f'{item_id}'].update(y, y_pred_lm)\n",
    "\n",
    "    # Store MAE of the linear model during training\n",
    "    mae.update(y, y_pred_lm)\n",
    "\n",
    "    dict_lm[f'{item_id}'].fit_one(x=x, y=y)\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "\n",
    "        bar.set_description(f'MAE, Linear Model: {mae.get():4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "scores_knn = {id: _.get() for id, _ in metric_knn.items()}\n",
    "\n",
    "scores_lm  = {id: _.get() for id, _ in metric_lm.items()}\n",
    "\n",
    "with open('scores_knn.json', 'w') as file:\n",
    "    \n",
    "    json.dump(scores_knn, file)\n",
    "\n",
    "with open('scores_lm.json', 'w') as file:\n",
    "    \n",
    "    json.dump(scores_lm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "# Per item name warning\n",
    "with open('dict_knn.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_knn, file)\n",
    "    \n",
    "with open('dict_lm.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_lm, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('scores_knn.json', 'rb') as file:\n",
    "    \n",
    "    scores_knn = json.load(file)\n",
    "\n",
    "with open('scores_lm.json', 'rb') as file:\n",
    "    \n",
    "    scores_lm = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('dict_knn.dill', 'rb') as file:\n",
    "    \n",
    "    dict_knn = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_lm.dill', 'rb') as file:\n",
    "    \n",
    "    dict_lm = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_models = {}\n",
    "\n",
    "for item_id in tqdm.tqdm(scores_knn.keys()):\n",
    "    \n",
    "    score_knn = scores_knn[item_id]\n",
    "    \n",
    "    score_lm  = scores_lm[item_id]\n",
    "    \n",
    "    if score_knn < score_lm:\n",
    "        \n",
    "        dict_models[item_id] = dict_knn[item_id]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        dict_models[item_id] = dict_lm[item_id]\n",
    "        \n",
    "# Save selected models:\n",
    "with open('dict_models.dill', 'wb') as file:\n",
    "    \n",
    "    dill.dump(dict_models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://159.89.38.125:8080'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [201]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import dill\n",
    "\n",
    "requests.post(f'{url}/api/init', json= {'flavor': 'regression'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_models.dill', 'rb') as file:\n",
    "    \n",
    "    dict_models = dill.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 15949/30490 [3:34:29<3:49:30,  1.06it/s]"
     ]
    }
   ],
   "source": [
    "for model_name, model in tqdm.tqdm(dict_models.items(), position=0):\n",
    "    \n",
    "    r = requests.post(f'{url}/api/model/{model_name}', data=dill.dumps(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction by calling the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/predict', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001_CA_1',\n",
    "    'features': {'date': '2016-05-23', 'id': 'HOBBIES_1_001_CA_1'}\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update models with new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.post(f'{url}/api/learn', json={\n",
    "    'id': 1,\n",
    "    'model': 'HOBBIES_1_001_CA_1',\n",
    "    'ground_truth': 0,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
